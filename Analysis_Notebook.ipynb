{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b52222ed",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81f93c",
   "metadata": {},
   "source": [
    "This notebook is NEW CONTINUING: I am piping in data objects created from other notebooks and analyzing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55793b4e",
   "metadata": {},
   "source": [
    "I will be combining datasets here and analyzing them based on my research questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8baaf3",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce5d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcbb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data frames\n",
    "\n",
    "f1 = open('characters_update_df.pkl', 'rb')\n",
    "characters_df = pickle.load(f1)\n",
    "f1.close()\n",
    "\n",
    "f2 = open('conversations_df.pkl', 'rb')\n",
    "conversations_df = pickle.load(f2)\n",
    "f2.close()\n",
    "\n",
    "f3 = open('movies_df.pkl', 'rb')\n",
    "movies_df = pickle.load(f3)\n",
    "f3.close\n",
    "\n",
    "# load in utterances from csv\n",
    "utterances_df = pd.read_csv('./private/utterances_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1337c5",
   "metadata": {},
   "source": [
    "Let's make sure they all look okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4a93e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_ID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>movie_ID</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u4</td>\n",
       "      <td>JOEY</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u5</td>\n",
       "      <td>KAT</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u6</td>\n",
       "      <td>MANDELLA</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character_ID character_name movie_ID                 movie_title gender\n",
       "0           u0         BIANCA       m0  10 things i hate about you      F\n",
       "2           u2        CAMERON       m0  10 things i hate about you      M\n",
       "4           u4           JOEY       m0  10 things i hate about you      M\n",
       "5           u5            KAT       m0  10 things i hate about you      F\n",
       "6           u6       MANDELLA       m0  10 things i hate about you      F"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd21267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_ID</th>\n",
       "      <th>character1_ID</th>\n",
       "      <th>character2_ID</th>\n",
       "      <th>movie_ID</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>L198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_ID character1_ID character2_ID movie_ID dialogue\n",
       "0                0            u0            u2       m0     L194\n",
       "0                0            u0            u2       m0     L195\n",
       "0                0            u0            u2       m0     L196\n",
       "0                0            u0            u2       m0     L197\n",
       "1                1            u0            u2       m0     L198"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11945e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>1999</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1492: conquest of paradise</td>\n",
       "      <td>1992</td>\n",
       "      <td>['adventure', 'biography', 'drama', 'history']</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15 minutes</td>\n",
       "      <td>2001</td>\n",
       "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001: a space odyssey</td>\n",
       "      <td>1968</td>\n",
       "      <td>['adventure', 'mystery', 'sci-fi']</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48 hrs.</td>\n",
       "      <td>1982</td>\n",
       "      <td>['action', 'comedy', 'crime', 'drama', 'thrill...</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  movie_title  movie_year  \\\n",
       "0  10 things i hate about you        1999   \n",
       "1  1492: conquest of paradise        1992   \n",
       "2                  15 minutes        2001   \n",
       "3       2001: a space odyssey        1968   \n",
       "4                     48 hrs.        1982   \n",
       "\n",
       "                                              genres  movie_decade  \n",
       "0                              ['comedy', 'romance']          1990  \n",
       "1     ['adventure', 'biography', 'drama', 'history']          1990  \n",
       "2           ['action', 'crime', 'drama', 'thriller']          2000  \n",
       "3                 ['adventure', 'mystery', 'sci-fi']          1960  \n",
       "4  ['action', 'comedy', 'crime', 'drama', 'thrill...          1980  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07eeccba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_ID</th>\n",
       "      <th>character_ID</th>\n",
       "      <th>movie_ID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>utterance</th>\n",
       "      <th>sents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>avg_sent_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>['They do not!']</td>\n",
       "      <td>['They', 'do', 'not', '!']</td>\n",
       "      <td>[(They, 'PRON'), (do, 'VERB'), (not, 'PART'), ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>['They do to!']</td>\n",
       "      <td>['They', 'do', 'to', '!']</td>\n",
       "      <td>[(They, 'PRON'), (do, 'VERB'), (to, 'PART'), (...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>['I hope so.']</td>\n",
       "      <td>['I', 'hope', 'so', '.']</td>\n",
       "      <td>[(I, 'PRON'), (hope, 'VERB'), (so, 'ADV'), (.,...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>['She okay?']</td>\n",
       "      <td>['She', 'okay', '?']</td>\n",
       "      <td>[(She, 'PRON'), (okay, 'ADJ'), (?, 'PUNCT')]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>[\"Let's go.\"]</td>\n",
       "      <td>['Let', \"'s\", 'go', '.']</td>\n",
       "      <td>[(Let, 'VERB'), ('s, 'PRON'), (go, 'VERB'), (....</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  line_ID character_ID movie_ID character_name     utterance  \\\n",
       "0   L1045           u0       m0         BIANCA  They do not!   \n",
       "1   L1044           u2       m0        CAMERON   They do to!   \n",
       "2    L985           u0       m0         BIANCA    I hope so.   \n",
       "3    L984           u2       m0        CAMERON     She okay?   \n",
       "4    L925           u0       m0         BIANCA     Let's go.   \n",
       "\n",
       "              sents                      tokens  \\\n",
       "0  ['They do not!']  ['They', 'do', 'not', '!']   \n",
       "1   ['They do to!']   ['They', 'do', 'to', '!']   \n",
       "2    ['I hope so.']    ['I', 'hope', 'so', '.']   \n",
       "3     ['She okay?']        ['She', 'okay', '?']   \n",
       "4     [\"Let's go.\"]    ['Let', \"'s\", 'go', '.']   \n",
       "\n",
       "                                             pos_tag  sent_count  token_count  \\\n",
       "0  [(They, 'PRON'), (do, 'VERB'), (not, 'PART'), ...           1            4   \n",
       "1  [(They, 'PRON'), (do, 'VERB'), (to, 'PART'), (...           1            4   \n",
       "2  [(I, 'PRON'), (hope, 'VERB'), (so, 'ADV'), (.,...           1            4   \n",
       "3       [(She, 'PRON'), (okay, 'ADJ'), (?, 'PUNCT')]           1            3   \n",
       "4  [(Let, 'VERB'), ('s, 'PRON'), (go, 'VERB'), (....           1            4   \n",
       "\n",
       "   avg_sent_length  \n",
       "0              4.0  \n",
       "1              4.0  \n",
       "2              4.0  \n",
       "3              3.0  \n",
       "4              4.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a849a42",
   "metadata": {},
   "source": [
    "utterance df will have to be POS tagged within the analysis document..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d02d515",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-22-2577047198b6>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    utterances_df['pos_tag'] = utterances_df['pos_tag'].fillna(\"[]\").apply(lambda x: eval(x))\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\"\u001b[0m, line \u001b[1;32m4771\u001b[0m, in \u001b[1;35mapply\u001b[0m\n    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\"\u001b[0m, line \u001b[1;32m1123\u001b[0m, in \u001b[1;35mapply\u001b[0m\n    return self.apply_standard()\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\"\u001b[0m, line \u001b[1;32m1174\u001b[0m, in \u001b[1;35mapply_standard\u001b[0m\n    mapped = lib.map_infer(\n",
      "  File \u001b[1;32m\"pandas/_libs/lib.pyx\"\u001b[0m, line \u001b[1;32m2924\u001b[0m, in \u001b[1;35mpandas._libs.lib.map_infer\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-2577047198b6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0;36m, in \u001b[0;35m<lambda>\u001b[0;36m\u001b[0m\n\u001b[0;31m    utterances_df['pos_tag'] = utterances_df['pos_tag'].fillna(\"[]\").apply(lambda x: eval(x))\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [(They, 'PRON'), (do, 'VERB'), (not, 'PART'), (!, 'PUNCT')]\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# the pos_tag column is not working as a list of tuples\n",
    "utterances_df['pos_tag'] = utterances_df['pos_tag'].fillna(\"[]\").apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfe9d4",
   "metadata": {},
   "source": [
    "They all look good I will review some basic information about the data and then compile the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd2981",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9195752",
   "metadata": {},
   "source": [
    "Let's review some basic information about the corpus before diving in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff481ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many movies in the corpus?\n",
    "movies_df.movie_title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab108b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the earliest year represented?\n",
    "movies_df.movie_year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc67fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the latest year represented?\n",
    "movies_df.movie_year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f563b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many characters are in the corpus?\n",
    "characters_df.character_name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many utterances?\n",
    "utterances_df.line_ID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tokens?\n",
    "utterances_df.token_count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed00674",
   "metadata": {},
   "source": [
    "## Compiling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd4b54",
   "metadata": {},
   "source": [
    "### Linguistic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612b9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because I am looking at discourse, I will use the utterances data frame and load other data into it\n",
    "\n",
    "# adding gender\n",
    "discourse_df = pd.merge(utterances_df, characters_df)\n",
    "\n",
    "# adding movie year and decade\n",
    "discourse_df = pd.merge(discourse_df, movies_df)\n",
    "\n",
    "# adding conversation data\n",
    "discourse_df = pd.merge(discourse_df, conversations_df, left_on='line_ID', right_on='dialogue').drop(columns=['character1_ID', 'character2_ID', 'movie_ID_y', 'dialogue'], axis=1)\n",
    "\n",
    "#rename column\n",
    "discourse_df.rename(columns={\"movie_ID_x\": \"movie_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94ba624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 267 utterances that are empty, I will remove them\n",
    "discourse_df = discourse_df[discourse_df.token_count != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c22d05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_ID</th>\n",
       "      <th>character_ID</th>\n",
       "      <th>movie_ID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>utterance</th>\n",
       "      <th>sents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_decade</th>\n",
       "      <th>conversation_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>['They do not!']</td>\n",
       "      <td>['They', 'do', 'not', '!']</td>\n",
       "      <td>[(They, 'PRON'), (do, 'VERB'), (not, 'PART'), ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "      <td>1999</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>1990</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>['I hope so.']</td>\n",
       "      <td>['I', 'hope', 'so', '.']</td>\n",
       "      <td>[(I, 'PRON'), (hope, 'VERB'), (so, 'ADV'), (.,...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "      <td>1999</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>1990</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>[\"Let's go.\"]</td>\n",
       "      <td>['Let', \"'s\", 'go', '.']</td>\n",
       "      <td>[(Let, 'VERB'), ('s, 'PRON'), (go, 'VERB'), (....</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "      <td>1999</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>[\"Okay -- you're gonna need to learn how to li...</td>\n",
       "      <td>['Okay', '--', 'you', \"'re\", 'gon', 'na', 'nee...</td>\n",
       "      <td>[(Okay, 'INTJ'), (--, 'PUNCT'), (you, 'PRON'),...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "      <td>1999</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>[\"I'm kidding.\", 'You know how sometimes you j...</td>\n",
       "      <td>['I', \"'m\", 'kidding', '.', 'You', 'know', 'ho...</td>\n",
       "      <td>[(I, 'PRON'), ('m, 'AUX'), (kidding, 'VERB'), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "      <td>1999</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  line_ID character_ID movie_ID character_name  \\\n",
       "0   L1045           u0       m0         BIANCA   \n",
       "1    L985           u0       m0         BIANCA   \n",
       "2    L925           u0       m0         BIANCA   \n",
       "3    L872           u0       m0         BIANCA   \n",
       "4    L870           u0       m0         BIANCA   \n",
       "\n",
       "                                           utterance  \\\n",
       "0                                       They do not!   \n",
       "1                                         I hope so.   \n",
       "2                                          Let's go.   \n",
       "3     Okay -- you're gonna need to learn how to lie.   \n",
       "4  I'm kidding.  You know how sometimes you just ...   \n",
       "\n",
       "                                               sents  \\\n",
       "0                                   ['They do not!']   \n",
       "1                                     ['I hope so.']   \n",
       "2                                      [\"Let's go.\"]   \n",
       "3  [\"Okay -- you're gonna need to learn how to li...   \n",
       "4  [\"I'm kidding.\", 'You know how sometimes you j...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                         ['They', 'do', 'not', '!']   \n",
       "1                           ['I', 'hope', 'so', '.']   \n",
       "2                           ['Let', \"'s\", 'go', '.']   \n",
       "3  ['Okay', '--', 'you', \"'re\", 'gon', 'na', 'nee...   \n",
       "4  ['I', \"'m\", 'kidding', '.', 'You', 'know', 'ho...   \n",
       "\n",
       "                                             pos_tag  sent_count  token_count  \\\n",
       "0  [(They, 'PRON'), (do, 'VERB'), (not, 'PART'), ...           1            4   \n",
       "1  [(I, 'PRON'), (hope, 'VERB'), (so, 'ADV'), (.,...           1            4   \n",
       "2  [(Let, 'VERB'), ('s, 'PRON'), (go, 'VERB'), (....           1            4   \n",
       "3  [(Okay, 'INTJ'), (--, 'PUNCT'), (you, 'PRON'),...           1           13   \n",
       "4  [(I, 'PRON'), ('m, 'AUX'), (kidding, 'VERB'), ...           3           25   \n",
       "\n",
       "   avg_sent_length                 movie_title gender  movie_year  \\\n",
       "0         4.000000  10 things i hate about you      F        1999   \n",
       "1         4.000000  10 things i hate about you      F        1999   \n",
       "2         4.000000  10 things i hate about you      F        1999   \n",
       "3        13.000000  10 things i hate about you      F        1999   \n",
       "4         8.333333  10 things i hate about you      F        1999   \n",
       "\n",
       "                  genres  movie_decade  conversation_ID  \n",
       "0  ['comedy', 'romance']          1990               24  \n",
       "1  ['comedy', 'romance']          1990               23  \n",
       "2  ['comedy', 'romance']          1990               22  \n",
       "3  ['comedy', 'romance']          1990               21  \n",
       "4  ['comedy', 'romance']          1990               21  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discourse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "022bd525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>movie_decade</th>\n",
       "      <th>conversation_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>304403.000000</td>\n",
       "      <td>304403.000000</td>\n",
       "      <td>304403.000000</td>\n",
       "      <td>304403.000000</td>\n",
       "      <td>304403.000000</td>\n",
       "      <td>304403.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.695433</td>\n",
       "      <td>13.736120</td>\n",
       "      <td>7.856031</td>\n",
       "      <td>1988.106428</td>\n",
       "      <td>1983.434822</td>\n",
       "      <td>41482.442111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.252371</td>\n",
       "      <td>14.712649</td>\n",
       "      <td>5.155597</td>\n",
       "      <td>17.141863</td>\n",
       "      <td>17.204418</td>\n",
       "      <td>23872.389444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1927.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>20784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>41575.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>62115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>684.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>83096.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sent_count    token_count  avg_sent_length     movie_year  \\\n",
       "count  304403.000000  304403.000000    304403.000000  304403.000000   \n",
       "mean        1.695433      13.736120         7.856031    1988.106428   \n",
       "std         1.252371      14.712649         5.155597      17.141863   \n",
       "min         1.000000       1.000000         1.000000    1927.000000   \n",
       "25%         1.000000       5.000000         4.500000    1984.000000   \n",
       "50%         1.000000       9.000000         7.000000    1995.000000   \n",
       "75%         2.000000      17.000000        10.000000    1999.000000   \n",
       "max        45.000000     684.000000       122.000000    2010.000000   \n",
       "\n",
       "        movie_decade  conversation_ID  \n",
       "count  304403.000000    304403.000000  \n",
       "mean     1983.434822     41482.442111  \n",
       "std        17.204418     23872.389444  \n",
       "min      1920.000000         0.000000  \n",
       "25%      1980.000000     20784.000000  \n",
       "50%      1990.000000     41575.000000  \n",
       "75%      1990.000000     62115.000000  \n",
       "max      2010.000000     83096.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discourse_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a8e68",
   "metadata": {},
   "source": [
    "Per turn there is a wide range on the token counts, from 1 to 684. There is also a wide range per turn on sentence counts, from 1 to 45. I need to decide if I will include the max values in my analysis to follow. For now they will remain in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd63fce",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d9702",
   "metadata": {},
   "source": [
    "I am looking at token counts to see if there is a difference between turns by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278415b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby('gender').token_count.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c78d71",
   "metadata": {},
   "source": [
    "Only 0.79 difference between average token counts of male and female characters. Characters with unknown gender markers have the longest turns at 14.7. Female characters have the shortest tokens per turn. Female and ambiguous characters fall below the mean and male and unknown are above the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2340fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw counts of tokens across the corpus\n",
    "discourse_df.groupby('gender').token_count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc7e2b9",
   "metadata": {},
   "source": [
    "Raw count doesn't help for comparison across categories, but by looking at this we can see that there are more male characters because the average token count above does not differ as much as the raw counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2bbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shortest turn by token count?\n",
    "discourse_df.groupby('gender').token_count.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda3fc3f",
   "metadata": {},
   "source": [
    "Characters across all gender markers have utterances that are only one token long. I expect these will be interjections of some kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebea07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df[discourse_df.token_count==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6f4d8",
   "metadata": {},
   "source": [
    "At quick glance, some answers and greetings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2765aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the longest turn by token count?\n",
    "discourse_df.groupby('gender').token_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the longest token count per utterance\n",
    "discourse_df[discourse_df.token_count==684]\n",
    "# seems like it may be a narration intro...it may be removed from analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a546b13",
   "metadata": {},
   "source": [
    "At the total corpus level there are some small differences between gender at the token level. I will factor in movie decade to see if any differences can be detected across time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f379b8",
   "metadata": {},
   "source": [
    "#### Token and Movie Decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b972aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discourse_df.groupby(['movie_decade','gender']).token_count.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cdf7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby(['movie_decade','gender']).token_count.min()\n",
    "# looks like not all movies have as short of utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby(['movie_decade','gender']).token_count.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9251b0e",
   "metadata": {},
   "source": [
    "#### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many sentences per turn?\n",
    "discourse_df.groupby('gender').sent_count.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310517d",
   "metadata": {},
   "source": [
    "The average utterance is less than two sentences long. There is not much difference across the categories. On average, male utterances have slightly more sentences. Again, unknown gender has the most (but barely) average sentences per utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d392e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby('gender').sent_count.sum()\n",
    "# more sentences for male characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d14131",
   "metadata": {},
   "source": [
    "This is another view of what we saw above: there are more male characters, which is why the raw sentence count is higher but not the average sentence count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf26e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tokens per sentence?\n",
    "discourse_df.groupby('gender').avg_sent_length.mean()\n",
    "# average sentence length across all genders does not seem to be too wide of a spread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7ff7d",
   "metadata": {},
   "source": [
    "For each gender, sentences have on average around 8 words, although female characters have the shortest averages sentences at 7.67."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b08c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby('gender').sent_count.max()\n",
    "# the longest turn by number of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be3a5d",
   "metadata": {},
   "source": [
    "Commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1deba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df[(discourse_df.sent_count==18) & (discourse_df.gender=='A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df[(discourse_df.sent_count==33) & (discourse_df.gender=='F')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b363cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df[discourse_df.sent_count==45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb09598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discourse_df[(discourse_df.sent_count==24) & (discourse_df.gender=='unknown')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6616e5a0",
   "metadata": {},
   "source": [
    "The longest utterance by sentence and longest utterance by token count are from male characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285d6d7",
   "metadata": {},
   "source": [
    "#### Sentences and Movie Decade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13549db",
   "metadata": {},
   "source": [
    "How does the sentence level information change by decade?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba14762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discourse_df.groupby(['movie_decade','gender']).sent_count.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33780a",
   "metadata": {},
   "source": [
    "COMMENTARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e2f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discourse_df.groupby(['movie_decade','gender']).sent_count.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98441bd5",
   "metadata": {},
   "source": [
    "COMMENTARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00a930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discourse_df.groupby(['movie_decade','gender']).sent_count.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104957cf",
   "metadata": {},
   "source": [
    "COMMENTARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68540739",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby(['movie_decade', 'gender']).avg_sent_length.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d3d5f",
   "metadata": {},
   "source": [
    "COMMENTARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdc449",
   "metadata": {},
   "source": [
    "#### POS\n",
    "\n",
    "I will ignore noun and verbs, as they are the most basic elements of phrase structure. I will look at adjectives and adverbs to see how often the speaker modifies their words, interjections to check for interruptions, and conjunctions to get an idea about sentence complexity.\n",
    "\n",
    "The parts of speech I will look at are the following:\n",
    "* ADV (adverb)\n",
    "* ADJ (adjective)\n",
    "* CCONJ (coordinating conjunction)\n",
    "* INTJ (interjection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22b951c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_ID</th>\n",
       "      <th>character_ID</th>\n",
       "      <th>movie_ID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>utterance</th>\n",
       "      <th>sents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_decade</th>\n",
       "      <th>conversation_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>['They do not!']</td>\n",
       "      <td>['They', 'do', 'not', '!']</td>\n",
       "      <td>[(They, 'PRON'), (do, 'VERB'), (not, 'PART'), ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>F</td>\n",
       "      <td>1999</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "      <td>1990</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  line_ID character_ID movie_ID character_name     utterance  \\\n",
       "0   L1045           u0       m0         BIANCA  They do not!   \n",
       "\n",
       "              sents                      tokens  \\\n",
       "0  ['They do not!']  ['They', 'do', 'not', '!']   \n",
       "\n",
       "                                             pos_tag  sent_count  token_count  \\\n",
       "0  [(They, 'PRON'), (do, 'VERB'), (not, 'PART'), ...           1            4   \n",
       "\n",
       "   avg_sent_length                 movie_title gender  movie_year  \\\n",
       "0              4.0  10 things i hate about you      F        1999   \n",
       "\n",
       "                  genres  movie_decade  conversation_ID  \n",
       "0  ['comedy', 'romance']          1990               24  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discourse_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f93e79e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'('"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad6f7e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1afce97b645c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# adding data to the data frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdiscourse_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adv_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscourse_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-1afce97b645c>\u001b[0m in \u001b[0;36mget_adv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_adv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'ADV'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0madvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-1afce97b645c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_adv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'ADV'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0madvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# adverbs\n",
    "def get_adv(x):\n",
    "    pattern = r'ADV'\n",
    "    advs = re.findall(pattern, ' '.join(str(z) for (y,z) in x))\n",
    "    return advs\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['adv_count'] = discourse_df.pos_tag.apply(get_adv).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61826d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjectives\n",
    "def get_adj(x):\n",
    "    pattern = r'ADJ'\n",
    "    adjs = re.findall(pattern, ' '.join(str(z) for (y,z) in x))\n",
    "    return adjs\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['adj_count'] = discourse_df.pos_tag.apply(get_adj).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conjunctions\n",
    "def get_conj(x):\n",
    "    pattern = r'CONJ'\n",
    "    conjs = re.findall(pattern, ' '.join(str(z) for (y,z) in x))\n",
    "    return conjs\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['conj_count'] = discourse_df.pos_tag.apply(get_conj).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interjections\n",
    "def get_intj(x):\n",
    "    pattern = r'INTJ'\n",
    "    intjs = re.findall(pattern, ' '.join(str(z) for (y,z) in x))\n",
    "    return intjs\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['intj_count'] = discourse_df.pos_tag.apply(get_intj).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac22a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3914da",
   "metadata": {},
   "source": [
    "Let's see how each gender uses these different parts of speech. Because the POS I am analyzing are not required, the usages may be low and a min of 0 per turn can be expected. This is indicated by flashing the head of the data frame above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e53833",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are',discourse_df.rb_count.sum(),'adverbs in the corpus.')\n",
    "print('There are',discourse_df.jj_count.sum(),'adjectives in the corpus.')\n",
    "print('There are',discourse_df.cc_count.sum(),'conjunctions in the corpus.')\n",
    "print('There are',discourse_df.uh_count.sum(),'interjections in the corpus.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e0c02",
   "metadata": {},
   "source": [
    "Adverbs are by far the most common POS out of the four selected for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby('gender').agg({'rb_count': ['mean', 'min', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef957b",
   "metadata": {},
   "source": [
    "Female characters have the highest mean of adverb usage at 0.97. So on avarage, almost every turn a female character will use an adverb in this corpus. However, the highest number of adverbs in one turn is from a male character with 35.\n",
    "\n",
    "As the boxplot shows the tails across all genders are very long. The turns with 0 instances are bringing down the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91689fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=discourse_df, x='gender', y='rb_count', kind='box')\n",
    "plt.title('Adverb Usage by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7657eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby('gender').agg({'jj_count': ['mean', 'min', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87041c0f",
   "metadata": {},
   "source": [
    "Characters with unknown gender have the highest mean usage of adjectives at .66, they also have the largest standard deviation, so there is most variability in these character's usage. Again, the most adjectives in a turn is from a male character with 53."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=discourse_df, x='gender', y='jj_count', kind='box')\n",
    "plt.title('Adjective Usage by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby('gender').agg({'cc_count': ['mean', 'min', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05555fd3",
   "metadata": {},
   "source": [
    "'Unknown' characters have the most conjunctions, but only by 0.01. Overall usage seems to be very consistent across the board. Once again, male characters have the highest number of conjunctions for one turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79688c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=discourse_df, x='gender', y='jj_count', kind='box')\n",
    "plt.title('Conjunction Usage by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9786eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.groupby('gender').agg({'uh_count': ['mean', 'min', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b2e72",
   "metadata": {},
   "source": [
    "Very low usage across the board, with female being the higest at 0.08. Both male and female characters have 7 interjections as a maximum per turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad408d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=discourse_df, x='gender', y='uh_count', kind='box')\n",
    "plt.title('Interjection Usage by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d187a",
   "metadata": {},
   "source": [
    "#### Lexical Items\n",
    "\n",
    "I will look to see if these hedging words appear more in one specific gender's speech or not:\n",
    "* I guess\n",
    "* I think\n",
    "* Maybe\n",
    "* Might\n",
    "* Perhaps\n",
    "* Possibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i guess\n",
    "def get_guess(x):\n",
    "    pattern = r'\\\\bI guess\\\\b'\n",
    "    guesses = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return guesses\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['guess_count'] = discourse_df.tokens.apply(get_guess).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think\n",
    "def get_think(x):\n",
    "    pattern = r'\\\\bI think\\\\b'\n",
    "    thinks = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return thinks\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['think_count'] = discourse_df.tokens.apply(get_think).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6cf45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe\n",
    "def get_maybe(x):\n",
    "    pattern = r'\\\\b[mM]aybe\\\\b'\n",
    "    maybes = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return maybes\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['maybe_count'] = discourse_df.tokens.apply(get_maybe).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ad96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might\n",
    "def get_might(x):\n",
    "    pattern = r'\\\\b[mM]ight\\\\b'\n",
    "    mights = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return mights\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['might_count'] = discourse_df.tokens.apply(get_might).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b307192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps\n",
    "def get_perhaps(x):\n",
    "    pattern = r'\\\\b[pP]erhaps\\\\b'\n",
    "    perhapses = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return perhapses\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['perhaps_count'] = discourse_df.tokens.apply(get_perhaps).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ea1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly\n",
    "def get_possibly(x):\n",
    "    pattern = r'\\\\b[pP]ossibly\\\\b'\n",
    "    possiblys = re.findall(pattern, ' '.join(str(y) for y in x))\n",
    "    return possiblys\n",
    "\n",
    "# adding data to the data frames\n",
    "discourse_df['possibly_count'] = discourse_df.tokens.apply(get_possibly).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491badda",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_df.maybe_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7553a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f53b9be0",
   "metadata": {},
   "source": [
    "### Gender/Movie Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it may be interesting to see character/gender information by year/decade\n",
    "\n",
    "gender_df = pd.merge(characters_df, movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2570fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df.groupby(['movie_decade', 'gender']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f127d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df[gender_df.movie_decade==1920]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e540c4",
   "metadata": {},
   "source": [
    "Aside from the 1920s, which only had two movies, all other decades have more male characters than female characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af081c",
   "metadata": {},
   "source": [
    "## Conversations between genders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033f05f",
   "metadata": {},
   "source": [
    "I will add gender markers to the conversation_df and see how the conversations are split up by the gender of each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665775c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gender for character1_ID\n",
    "conversations_df = pd.merge(conversations_df, characters_df, left_on='character1_ID', right_on='character_ID').drop(columns=['movie_ID_y', 'movie_title', 'character_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef85c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gender for character2_ID\n",
    "conversations_df = pd.merge(conversations_df, characters_df, left_on='character2_ID', right_on='character_ID').drop(columns=['movie_ID', 'movie_title', 'character_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything got merged, lets rename the columns to tidy up some\n",
    "conversations_df.rename(columns={\"movie_ID_x\": \"movie_ID\", \"character_name_x\": \"character1_name\", \"gender_x\": \"gender1\", \"character_name_y\": \"character2_name\", \"gender_y\": \"gender2\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48125168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the columns\n",
    "conversations_df = conversations_df[['character1_ID', 'character1_name', 'gender1', 'character2_ID', 'character2_name', 'gender2', 'movie_ID', 'dialogue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bceeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482c1dc",
   "metadata": {},
   "source": [
    "Possible gender pairings:\n",
    "\n",
    "A - A<br>\n",
    "F - F<br>\n",
    "M - M<br>\n",
    "U - U<br>\n",
    "A - F<br>\n",
    "A - M<br>\n",
    "A - U<br>\n",
    "F - M<br>\n",
    "F - U<br>\n",
    "M - U<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return conversational gender pairs\n",
    "def gender_pairs(a, b):\n",
    "    if a == 'M' and b == 'F' or a == 'F' and b == 'M':\n",
    "        return 'F:M'\n",
    "    elif a == 'M' and b == 'A' or a == 'A' and b == 'M':\n",
    "        return 'A:M'\n",
    "    elif a == 'M' and b == 'unknown' or a == 'unknown' and b == 'M':\n",
    "        return 'M:unknown'\n",
    "    elif a == 'A' and b =='F' or a == 'F' and b =='A':\n",
    "        return 'A:F'\n",
    "    elif a == 'A' and b == 'unknown' or a == 'unknown' and b == 'A':\n",
    "        return 'A:unknown'\n",
    "    elif a == 'F' and b == 'unknown' or a == 'unknown' and b == 'F':\n",
    "        return 'F:unknown'\n",
    "    elif a == 'A' and b == 'A':\n",
    "        return 'A:A'\n",
    "    elif a == 'F' and b == 'F':\n",
    "        return 'F:F'\n",
    "    elif a == 'M' and b == 'M':\n",
    "        return 'M:M'\n",
    "    else:\n",
    "        return 'unknown:unknown'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c320fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column combining gender pairs\n",
    "conversations_df['gender_pair'] = conversations_df.apply(lambda x: gender_pairs(a = x['gender1'], b = x['gender2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc344271",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_df.groupby('gender_pair').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"gender_pair\",\n",
    "             data = conversations_df)\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
